/**
 * API Chat - Endpoint pour chatbot GPT analysant BigQuery
 */

import { NextRequest, NextResponse } from 'next/server'
import { promises as fs } from 'fs'
import path from 'path'
import { route as routeIntent } from './intentRouter'
import { bigquery } from '@/lib/bigquery'

// Helper function pour ex√©cuter des requ√™tes
async function query(sql: string): Promise<any[]> {
  const [rows] = await bigquery.query({ query: sql })
  return rows
}

export const dynamic = 'force-dynamic'

// OpenAI sera initialis√© de mani√®re lazy dans la fonction POST
// pour √©viter les erreurs au build time

// ========================================
// PROMPT SYST√àME
// ========================================

const SYSTEM_PROMPT = `Tu es l‚ÄôAssistant Moverz.

PRINCIPES
1) Strat√©gie d‚Äôabord, toujours. Chaque r√©ponse commence par un court angle ‚ÄúStrat√©gie‚Äù (2‚Äì4 puces).
2) Si, et seulement si, la question n√©cessite des chiffres issus des sources de donn√©es, active le mode Data Moverz.
3) N‚Äôinvente pas : s‚Äôappuyer prioritairement sur dashboard/data/strategy.md + strategy.json.
4) Les donn√©es BigQuery ne sont consult√©es que lorsque l‚Äôintention ‚Äúdata‚Äù est confirm√©e ET que Data Moverz est activ√©.
5) Quand une ressource manque, indique pos√©ment quoi brancher (ex: ‚ÄúGA4 export‚Äù ou ‚Äúrepo GitHub‚Äù) et continue avec une r√©ponse strat√©gique exploitable.

MODES
- G√©n√©raliste (par d√©faut) : conversation, cadrage, priorisation, d√©cisions, plan d‚Äôaction. Jamais de SQL.
- Data Moverz : uniquement pour ‚Äútrafic/404/agents/GSC‚Äù etc. Fournis un r√©sum√© concis + possibilit√© de d√©tails via les boutons.

FORMAT DE R√âPONSE
- Section 1 ‚Äî ¬´ Strat√©gie ¬ª : 2‚Äì4 puces (hypoth√®ses, d√©cision, next step).
- Section 2 ‚Äî ¬´ Donn√©es ¬ª : incluse seulement si Data Moverz est actif (‚â§10 lignes).
- Section 3 ‚Äî ¬´ Prochaines actions ¬ª : 2‚Äì3 puces actionnables max.

COMPORTEMENTS INTERDITS
- Ne jamais lancer de SQL si l‚Äôintention ‚Äúdata‚Äù n‚Äôest pas confirm√©e.
- Ne pas afficher les boutons ‚ÄúD√©tailler / Deepsearch / Data‚Äù hors mode Data.
- Pas de bascule implicite vers Data sur un simple ‚Äúhello‚Äù, ‚Äúmerci‚Äù, ‚Äúparle-moi de‚Ä¶‚Äù.

RESSOURCES DISPONIBLES
- Strat√©gie (toujours) : dashboard/data/strategy.md et strategy.json.
- BigQuery (Data Moverz) : gsc_daily_aggregated, gsc_daily_metrics, errors_404_history, agent_insights, agent_runs.
- Fallback 404 : moverz.errors_404_history si analytics_core absent.

SI DOUTE
- Si l‚Äôintention est ambigu√´ (<0.75 de confiance), reste en G√©n√©raliste et propose une reformulation en 1 phrase pour pr√©ciser le besoin.`

// ========================================
// ENDPOINT POST
// ========================================

async function readStrategyContext(): Promise<{ markdown: string; json: string }> {
  try {
    // Try multiple locations (local build vs prod)
    const bases = [
      path.join(process.cwd(), 'dashboard', 'data'),
      path.join(process.cwd(), 'data'),
      path.join(process.cwd(), 'dashboard', 'dashboard', 'data'),
    ]
    let markdown = ''
    let json = ''
    for (const b of bases) {
      if (!markdown) markdown = await fs.readFile(path.join(b, 'strategy.md'), 'utf-8').catch(() => '')
      if (!json) json = await fs.readFile(path.join(b, 'strategy.json'), 'utf-8').catch(() => '')
    }
    // Fallback env
    if (!markdown && process.env.STRATEGY_MD) markdown = process.env.STRATEGY_MD
    if (!json && process.env.STRATEGY_JSON) json = process.env.STRATEGY_JSON
    return { markdown, json }
  } catch {
    return { markdown: '', json: '' }
  }
}

export async function POST(request: NextRequest) {
  try {
    // V√©rifier et initialiser OpenAI (lazy, uniquement au runtime)
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { success: false, error: 'OpenAI API key not configured' },
        { status: 503 }
      )
    }

    // Import dynamique d'OpenAI uniquement au runtime (√©vite erreur au build)
    const { default: OpenAI } = await import('openai')
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    const body = await request.json()
    const { message, mode = 'summary', context, dataMode = false } = body as { message: string; mode?: 'summary' | 'detail' | 'deepsearch' | 'data'; context?: any; dataMode?: boolean }

    // Route intent
    const routed = routeIntent(message, dataMode)

    if (!message) {
      return NextResponse.json(
        { success: false, error: 'Message required' },
        { status: 400 }
      )
    }

    // D√©tection simple du sujet pour aiguiller le prompt
    const lower = message.toLowerCase()
    // Heuristique de m√©trique demand√©e
    const metric: 'impressions' | 'clicks' | 'ctr' | 'position' = /impression/.test(lower)
      ? 'impressions'
      : /ctr/.test(lower)
      ? 'ctr'
      : /position|rank|ranking/.test(lower)
      ? 'position'
      : 'clicks'
    const isDataQuestion = routed.mode === 'data'
    const topic: 'traffic' | '404' | 'agents' = /404|broken|lien cass|crawl/.test(lower)
      ? '404'
      : /agent|insight|run|orchestrator/.test(lower)
      ? 'agents'
      : 'traffic'

    // G√©n√©raliste si router dit general
    if (routed.mode !== 'data') {
      const strategy = await readStrategyContext()
      const { default: OpenAI } = await import('openai')
      const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! })
      const generalResponse = await openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: 'Tu es un assistant business francophone. Tu utilises le contexte Strat√©gie ci-dessous pour r√©pondre de mani√®re concise (‚â§10 lignes). Si une info n\'est pas pr√©sente, dis-le clairement.' },
          { role: 'system', content: `STRAT√âGIE MARKDOWN:\n${strategy.markdown}` },
          { role: 'system', content: `STRAT√âGIE JSON:\n${strategy.json}` },
          { role: 'user', content: message },
        ],
        temperature: 0.5,
        max_tokens: 900,
      })
      let analysis = generalResponse.choices[0]?.message?.content || ''
      if (mode === 'summary') {
        analysis = analysis.split('\n').slice(0, 10).join('\n')
      }
      return NextResponse.json({ success: true, data: { sql: null, explanation: null, results: [], rowCount: 0, analysis, error: null, suggestions: [], topic: 'general', mode, extra: { strategyUsed: Boolean(strategy.markdown || strategy.json), routed } } })
    }

    // 1. Appeler GPT pour g√©n√©rer la requ√™te SQL
    console.log('ü§ñ Asking GPT for SQL query...')
    
    try {
      const chatResponse = await openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: SYSTEM_PROMPT + (mode === 'summary' ? '\n\nCONTRAINTE: La r√©ponse finale utilisateur doit tenir en 10 lignes max.' : '') },
          { role: 'user', content: `[TOPIC=${topic}] [METRIC=${metric}] ${message}` },
        ],
        temperature: 0.1, // Plus bas pour plus de coh√©rence
        max_tokens: 800,
        response_format: { type: 'json_object' },
      })

      const content = chatResponse.choices[0]?.message?.content
      console.log('GPT Response:', content)

      if (!content) {
        throw new Error('Empty response from GPT')
      }

      // Extraction JSON robuste (tol√®re ```json ... ```), sinon fallback constructeur SQL simple
      let gptResult: any
      try {
        gptResult = JSON.parse(content)
      } catch {
        const m = content.match(/```json\n([\s\S]*?)\n```/) || content.match(/{[\s\S]*}/)
        if (m) {
          gptResult = JSON.parse(m[1] ? m[1] : m[0])
        } else {
          // Fallback constructeur (topic trafic uniquement)
          const cityMap: Record<string, string> = {
            lyon: 'devis-demenageur-lyon.fr',
            toulouse: 'devis-demenageur-toulousain.fr',
            nantes: 'devis-demenageur-nantes.fr',
            marseille: 'www.bordeaux-demenageur.fr',
            bordeaux: 'www.bordeaux-demenageur.fr',
            nice: 'devis-demenageur-nice.fr',
            strasbourg: 'devis-demenageur-strasbourg.fr',
            rouen: 'devis-demenageur-rouen.fr',
            rennes: 'devis-demenageur-rennes.fr',
            montpellier: 'devis-demenageur-montpellier.fr',
            lille: 'devis-demenageur-lille.fr',
          }
          const foundCity = Object.keys(cityMap).find(c => lower.includes(c))
          const domainFilter = foundCity ? `AND domain = '${cityMap[foundCity]}'` : ''
          const days = /7\s?j|7\s?jours|\b7\b/.test(lower) ? 7 : 30
          const selectExpr = metric === 'impressions' ? 'SUM(impressions) as impressions' : metric === 'ctr' ? 'AVG(ctr) as ctr' : metric === 'position' ? 'AVG(position) as position' : 'SUM(clicks) as clicks'
          gptResult = {
            sql: `SELECT FORMAT_DATE('%Y-%m-%d', date) as date, ${selectExpr}\nFROM \`moverz-dashboard.analytics_core.gsc_daily_aggregated\`\nWHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL ${days} DAY)\n  AND date < DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)\n  ${domainFilter}\nGROUP BY date\nORDER BY date` ,
            explanation: 'Fallback constructeur: √©volution des clics sur la p√©riode demand√©e.',
            suggestions: [foundCity ? `Comparer ${foundCity} √† la moyenne r√©seau` : 'Pr√©ciser un domaine pour focaliser'],
          }
        }
      }

      let sql = gptResult.sql as string | undefined

      if (!sql) {
        console.warn('No SQL in response, using fallback query')
        // Fallback s√©curis√©: KPIs 7 jours par domaine
        sql = `SELECT domain, SUM(impressions) AS total_impressions, SUM(clicks) AS total_clicks, AVG(ctr) AS avg_ctr, AVG(position) AS avg_position FROM \`moverz-dashboard.analytics_core.gsc_daily_aggregated\` WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY) GROUP BY domain ORDER BY total_impressions DESC LIMIT 20`
        gptResult = {
          explanation: gptResult?.explanation || 'Fallback appliqu√©: KPIs globaux sur 7 jours par domaine.',
          suggestions: gptResult?.suggestions || [
            'Pr√©cisez un domaine (ex: "toulousain") pour une √©volution temporelle',
            'Demandez une comparaison 7j vs 7j pr√©c√©dents',
          ],
        }
      }

      console.log('üìä Generated SQL:', sql)

      // 2. Ex√©cuter la requ√™te BigQuery (avec fallback dataset pour 404) ‚Äî Data Gate
      let data = []
      let error = null

      try {
        data = await query(sql)
        console.log(`‚úÖ Query executed: ${data.length} rows returned`)
      } catch (queryError: any) {
        console.error('‚ùå Query error:', queryError.message)
        // Fallback si la table errors_404_history n'existe pas dans analytics_core
        const notFound = /Not found: Table .*errors_404_history/i.test(queryError.message || '')
        const targetsAnalyticsCore = /analytics_core\.errors_404_history/.test(sql)
        if (notFound && targetsAnalyticsCore) {
          const fallbackSql = sql.replace(/moverz-dashboard\.analytics_core\.errors_404_history/g, 'moverz.errors_404_history')
          console.warn('üîÅ Retrying with fallback dataset for errors_404_history:', fallbackSql)
          try {
            data = await query(fallbackSql)
            sql = fallbackSql
            error = null
            console.log(`‚úÖ Fallback query executed: ${data.length} rows returned`)
            // Enrichir l'explication
            gptResult.explanation = (gptResult.explanation ? gptResult.explanation + '\n' : '') +
              'Note: dataset fallback appliqu√© vers `moverz.errors_404_history`.'
          } catch (fallbackErr: any) {
            console.error('‚ùå Fallback query error:', fallbackErr.message)
            error = fallbackErr.message
          }
        } else {
          error = queryError.message
        }
      }

      // 2.b Deepsearch: ex√©cuter des requ√™tes suppl√©mentaires selon le sujet
      const extra: Record<string, any> = {}
      if (!error && mode === 'deepsearch') {
        try {
          if (topic === '404') {
            const q1 = 'SELECT DATE(scan_date) AS date, AVG(total_errors_404) AS avg_404 FROM `moverz-dashboard.analytics_core.errors_404_history` WHERE scan_date >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY) GROUP BY DATE(scan_date) ORDER BY date DESC LIMIT 30'
            const q1rows = await query(q1).catch(async () => await query(q1.replace(/moverz-dashboard\.analytics_core\.errors_404_history/g, 'moverz.errors_404_history')))
            extra.timeseries_404 = q1rows
          } else if (topic === 'traffic') {
            const q2 = 'SELECT domain, SUM(clicks) AS clicks, SUM(impressions) AS impressions FROM `moverz-dashboard.analytics_core.gsc_daily_aggregated` WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 14 DAY) GROUP BY domain ORDER BY impressions DESC LIMIT 20'
            extra.top_sites = await query(q2)
          } else if (topic === 'agents') {
            const q3 = 'SELECT agent_name, COUNT(*) AS runs, ROUND(AVG(duration_seconds),2) AS avg_s, ROUND(COUNTIF(status="success")/COUNT(*)*100,1) AS success_rate FROM `moverz-dashboard.analytics_core.agent_runs` WHERE executed_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY) GROUP BY agent_name ORDER BY runs DESC'
            extra.agent_stats = await query(q3)
          }
        } catch (e: any) {
          console.warn('Deepsearch extra queries failed:', e?.message)
        }
      }

      // 3. Analyser les r√©sultats avec GPT (enrichi du contexte Strat√©gie si disponible)
      let analysis = null
      
      if (!error && data.length > 0) {
        console.log('üß† Analyzing results with GPT...')
        
        const analysisPrompt = `
Tu es un expert en analytics web et SEO pour des sites de d√©m√©nagement.

Question pos√©e: "${message}"

R√©sultats de la requ√™te BigQuery:
${JSON.stringify(data, null, 2)}

INSTRUCTIONS CRITIQUES:
1. Toujours inclure les CHIFFRES EXACTS avec notation: "(X -> Y)"
2. Toujours calculer et afficher les VARIATIONS: "(+X% ou -X%)"
3. √ätre DENSE et DOCUMENT√â: donner faits, contexte, interpr√©tation
4. Utiliser format: "En baisse de 15% (120 ‚Üí 103 imp)" pour les comparaisons
5. Ajouter contexte sur CE QUE √áA SIGNIFIE
6. Proposer ACTIONS si pertinent

Exemple de bonne r√©ponse (format requis):
"
üìä **R√©sum√©**
Marseille: en baisse de 15% (8,420 ‚Üí 7,156 imp/jour). Perte de 1,264 impressions quotidiennes.

üîç **Interpr√©tation**
Cette baisse sugg√®re une r√©gression SEO: le site appara√Æt moins souvent dans les r√©sultats Google. Sur 7 jours, cela repr√©sente ~8,848 impressions perdues. Cette chute peut indiquer:
- D√©sindexation de pages
- Perte de ranking sur mots-cl√©s importants  
- Impact d'une mise √† jour technique r√©cente

üí° **Action recommand√©e**
V√©rifier les 10 derni√®res mises √† jour, audits crawl/404, positions historiques sur top 20 kw.
"

Exemple de mauvaise r√©ponse:
"Analyse compl√©t√©e."
`

      const strategy = await readStrategyContext()
      const analysisResponse = await openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4-turbo-preview',
        messages: [
          {
            role: 'system',
            content: 'Tu es un expert analytics et business qui explique les donn√©es clairement en fran√ßais. Utilise le contexte Strat√©gie si pertinent pour interpr√©ter (ne pas inventer).',
          },
          { role: 'system', content: strategy.markdown ? `STRAT√âGIE MARKDOWN:\n${strategy.markdown}` : '' },
          { role: 'system', content: strategy.json ? `STRAT√âGIE JSON:\n${strategy.json}` : '' },
          {
            role: 'user',
            content: analysisPrompt,
          },
        ],
        temperature: 0.7,
        max_tokens: 1500,
      })

      let analysisText = analysisResponse.choices[0]?.message?.content || ''
      if (mode === 'summary') {
        // S√©curit√©: tronquer √† 10 lignes max c√¥t√© API
        const lines = analysisText.split('\n')
        analysisText = lines.slice(0, 10).join('\n')
      }
      analysis = analysisText
      console.log('‚úÖ Analysis generated')
    } else if (error) {
      analysis = `‚ùå Erreur lors de l'ex√©cution de la requ√™te: ${error}\n\nJe ne peux pas analyser les donn√©es car la requ√™te a √©chou√©.`
    } else {
      analysis = `Aucune donn√©e trouv√©e pour votre question.\n\nEssayez de reformuler votre question ou d'utiliser des crit√®res diff√©rents.`
      }

      // 4. Retourner la r√©ponse
      return NextResponse.json({
      success: true,
      data: {
        sql,
        explanation: gptResult.explanation,
        results: data,
        rowCount: data.length,
        analysis,
        error,
        suggestions: gptResult.suggestions || [],
        topic,
        mode: 'data',
        extra: { ...extra, routed },
      },
      })

    } catch (gptError: any) {
      console.error('‚ùå GPT API error:', gptError)
      return NextResponse.json({
        success: false,
        error: `Erreur lors de la g√©n√©ration de la requ√™te: ${gptError.message}`,
      })
    }

  } catch (error: any) {
    console.error('‚ùå Chat API error:', error)
    return NextResponse.json(
      { success: false, error: error.message },
      { status: 500 }
    )
  }
}

