# ğŸ”„ ETL Usage Guide - Google Search Console â†’ BigQuery

Guide complet pour utiliser l'ETL V1 (table unique `gsc_daily_metrics`).

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Usage Quotidien](#-usage-quotidien)
2. [Ajouter un Domaine](#-ajouter-un-domaine)
3. [Backfill (Remplissage Historique)](#-backfill-remplissage-historique)
4. [Migration Multi-Tables (V2)](#-migration-multi-tables-v2)
5. [Troubleshooting](#-troubleshooting)

---

## ğŸš€ Usage Quotidien

### **Lancement Manuel (Local)**

```bash
# PrÃ©requis: fichier .env configurÃ©
npm install

# Lancer l'ETL une fois
npm run run:once

# RÃ©sultat attendu:
# âœ… 11 domaines traitÃ©s
# âœ… Milliers de lignes insÃ©rÃ©es dans BigQuery
# âœ… Code sortie: 0 (succÃ¨s)
```

### **Codes de Sortie**

| Code | Signification | Action |
|------|---------------|--------|
| `0` | âœ… SuccÃ¨s complet | RAS |
| `1` | âŒ Ã‰chec complet (auth, BQ indispo) | VÃ©rifier credentials |
| `2` | âš ï¸ SuccÃ¨s partiel (â‰¥1 domaine en erreur) | VÃ©rifier logs |

### **Cron CapRover (Production)**

**Configuration recommandÃ©e :**
```bash
# Cron: 15 3 * * *  (03:15 Europe/Paris)
# CMD: npm run run:once

# CapRover UI:
Apps â†’ dd-dashboard â†’ App Configs â†’ Persistent Apps
â†’ Ajouter Cron Job:
   Schedule: 15 3 * * *
   Command: npm run run:once
```

**Pourquoi 03:15 ?**
- GSC a ~48-72h de latence
- FenÃªtre glissante `FETCH_DAYS=3` rattrape le retard
- Heure creuse (peu de charge serveur)

---

## â• Ajouter un Domaine

### **Ã‰tape 1 : Autoriser le Service Account dans GSC**

1. **Aller dans Google Search Console**  
   â†’ https://search.google.com/search-console

2. **SÃ©lectionner la propriÃ©tÃ©** (ex: `devis-demenageur-dijon.fr`)

3. **ParamÃ¨tres â†’ Utilisateurs et autorisations**

4. **Ajouter un utilisateur :**
   - Email : `<votre-sa>@<project>.iam.gserviceaccount.com`
   - Permission : **PropriÃ©taire** (requis pour API)

5. **Valider**

### **Ã‰tape 2 : Ajouter le Domaine Ã  `SITES_LIST`**

**Via CapRover UI :**
```bash
# Apps â†’ dd-dashboard â†’ App Configs â†’ Environment Variables
SITES_LIST=devis-demenageur-marseille.fr,...,devis-demenageur-dijon.fr
```

**Ou via `.env` (local) :**
```bash
SITES_LIST=devis-demenageur-marseille.fr,devis-demenageur-toulousain.fr,devis-demenageur-lyon.fr,bordeaux-demenageur.fr,devis-demenageur-nantes.fr,devis-demenageur-lille.fr,devis-demenageur-nice.fr,devis-demenageur-strasbourg.fr,devis-demenageur-rouen.fr,devis-demenageur-rennes.fr,devis-demenageur-montpellier.fr,devis-demenageur-dijon.fr
```

### **Ã‰tape 3 : Tester**

```bash
# Lancer manuellement
npm run run:once

# VÃ©rifier logs
# Attendu: "Processing devis-demenageur-dijon.fr... âœ…"

# VÃ©rifier BigQuery
SELECT domain, COUNT(*) as rows
FROM `moverz-dashboard.analytics_core.gsc_daily_metrics`
WHERE domain = 'devis-demenageur-dijon.fr'
GROUP BY domain
```

**âœ… C'est tout !** Le nouveau domaine sera inclus dans les prochains runs.

---

## ğŸ”„ Backfill (Remplissage Historique)

### **Cas d'Usage**

- Nouveau domaine : remplir les 16 derniers mois (limite GSC)
- Ã‰chec ETL : re-remplir une pÃ©riode manquante
- Migration : synchroniser l'historique complet

### **Usage Basique**

```bash
# Backfill 30 derniers jours (tous les domaines)
npm run backfill -- --start 2024-12-01 --end 2024-12-31

# Backfill 1 domaine spÃ©cifique
npm run backfill -- \
  --start 2024-12-01 \
  --end 2024-12-31 \
  --domain devis-demenageur-marseille.fr

# Backfill 16 mois complets (limite GSC)
npm run backfill -- \
  --start 2023-09-01 \
  --end 2024-12-31 \
  --batch-size 7
```

### **Options**

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--start` | Date de dÃ©but (YYYY-MM-DD) | J-30 |
| `--end` | Date de fin (YYYY-MM-DD) | Aujourd'hui |
| `--domain` | Domaine spÃ©cifique (optionnel) | Tous (SITES_LIST) |
| `--batch-size` | Taille du batch en jours | 7 |

### **Limites GSC**

âš ï¸ **Google Search Console ne conserve que 16 mois d'historique.**

Si tu demandes `--start 2022-01-01`, le script ajustera automatiquement Ã  `J-16 mois`.

### **Performance**

**Batch Size :**
- `--batch-size 7` (dÃ©faut) : 7 jours par requÃªte â†’ 60 requÃªtes pour 1 an
- `--batch-size 30` : 30 jours par requÃªte â†’ 12 requÃªtes pour 1 an (plus rapide, mais risque timeout)

**Rate Limiting :**
- Pause de 2s entre chaque batch
- Exponential backoff sur HTTP 429

**DurÃ©e estimÃ©e :**
- 1 domaine, 30 jours : ~5 min
- 11 domaines, 16 mois : ~2-3h

### **Idempotence**

âœ… **Relancer un backfill n'insÃ¨re PAS de doublons.**

Le MERGE upsert sur `(date, domain, page, query)` garantit l'idempotence.

---

## ğŸ”„ Migration Multi-Tables (V2)

### **Pourquoi Migrer ?**

**V1 (Table Unique)** :
```sql
gsc_daily_metrics
â”œâ”€â”€ date, domain, page, query
â””â”€â”€ clicks, impressions, ctr, position
```

**V2 (3 Tables SÃ©parÃ©es)** :
```sql
gsc_global   â†’ MÃ©triques quotidiennes globales
gsc_pages    â†’ MÃ©triques par page
gsc_queries  â†’ MÃ©triques par requÃªte
```

**Avantages V2 :**
- âœ… **Tables plus petites** : Clustering + partitioning optimaux
- âœ… **Queries plus rapides** : Pas de `GROUP BY` coÃ»teux
- âœ… **SÃ©paration des concerns** : Global â‰  Pages â‰  Queries
- âœ… **Extensible** : Facilite l'ajout de dimensions (device, country)

**Quand migrer ?**
- Table `gsc_daily_metrics` > 10M lignes
- Queries lentes (>10s)
- Besoin d'ajouter des dimensions

### **Migration AutomatisÃ©e**

```bash
# Ã‰tape 1 : Dry-run (simulation)
npm run split-tables -- --dry-run

# Output attendu:
# [DRY-RUN] Would create table: gsc_global
# [DRY-RUN] Estimated rows to migrate: 2,345,678

# Ã‰tape 2 : Migration rÃ©elle (DESTRUCTIVE)
npm run split-tables -- --confirm

# Output attendu:
# âœ… Created table: gsc_global (1,234,567 rows)
# âœ… Created table: gsc_pages (8,765,432 rows)
# âœ… Created table: gsc_queries (9,876,543 rows)
# âœ… Validation OK: totals match
# âœ… Backup created: gsc_daily_metrics_backup
```

### **Ce Que Fait le Script**

1. **CrÃ©er nouvelles tables** (`gsc_global`, `gsc_pages`, `gsc_queries`)
2. **Migrer donnÃ©es** (INSERT INTO ... SELECT ... FROM `gsc_daily_metrics`)
3. **Valider totaux** (comparer clicks/impressions)
4. **Backup table originale** (`gsc_daily_metrics_backup`)

### **Rollback (si problÃ¨me)**

```sql
-- Supprimer nouvelles tables
DROP TABLE `moverz-dashboard.analytics_core.gsc_global`;
DROP TABLE `moverz-dashboard.analytics_core.gsc_pages`;
DROP TABLE `moverz-dashboard.analytics_core.gsc_queries`;

-- Restaurer backup (si nÃ©cessaire)
CREATE TABLE `moverz-dashboard.analytics_core.gsc_daily_metrics`
AS SELECT * FROM `moverz-dashboard.analytics_core.gsc_daily_metrics_backup`;
```

### **AprÃ¨s Migration**

**Mettre Ã  jour ETL :**
```bash
# Passer de fetch-simple.ts Ã  fetch.ts (multi-tables)
# Dans CapRover CMD:
npm run etl:gsc  # (au lieu de npm run run:once)
```

**Mettre Ã  jour Dashboard :**
```sql
-- Anciennes queries (V1)
SELECT domain, SUM(clicks), SUM(impressions)
FROM `gsc_daily_metrics`
GROUP BY domain

-- Nouvelles queries (V2)
SELECT site, clicks, impressions
FROM `gsc_global`
```

---

## ğŸ”§ Troubleshooting

### **Erreur : "GCP_SA_KEY_JSON is required"**

**Solution :**
```bash
# VÃ©rifier variable d'env
echo $GCP_SA_KEY_JSON

# Si vide, configurer dans CapRover UI:
Apps â†’ dd-dashboard â†’ App Configs â†’ Environment Variables
â†’ GCP_SA_KEY_JSON={"type":"service_account",...}
```

### **Erreur : "Permission denied (Search Console)"**

**Solution :**
1. VÃ©rifier que le Service Account est bien **PropriÃ©taire** dans GSC
2. Attendre 5-10 min (propagation IAM)
3. Relancer ETL

### **Erreur : "Rate limited (HTTP 429)"**

**Solution :**
- Le script gÃ¨re automatiquement (exponential backoff)
- Si persiste : rÃ©duire `--batch-size` dans backfill

### **DonnÃ©es manquantes (impressions = 0)**

**Causes :**
- GSC a ~48-72h de latence â†’ Normal pour J-1 / J-2
- Nouveau domaine â†’ Pas encore indexÃ©
- ProblÃ¨me sitemap â†’ VÃ©rifier GSC UI

**Solution :**
```bash
# Re-run ETL pour rattraper les donnÃ©es finales
npm run run:once
```

### **VÃ©rifier IntÃ©gritÃ© DonnÃ©es**

```sql
-- 1. VÃ©rifier cohÃ©rence clicks â‰¤ impressions
SELECT COUNT(*) as invalid_rows
FROM `moverz-dashboard.analytics_core.gsc_daily_metrics`
WHERE clicks > impressions;
-- Attendu: 0

-- 2. VÃ©rifier couverture par domaine
SELECT 
  domain,
  MIN(date) as first_date,
  MAX(date) as last_date,
  COUNT(DISTINCT date) as days_count
FROM `moverz-dashboard.analytics_core.gsc_daily_metrics`
GROUP BY domain;

-- 3. Comparer totaux avec GSC UI
SELECT 
  date,
  SUM(clicks) as total_clicks,
  SUM(impressions) as total_impressions
FROM `moverz-dashboard.analytics_core.gsc_daily_metrics`
WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
GROUP BY date
ORDER BY date DESC;
```

---

## ğŸ“Š Logs & Monitoring

### **Lire Logs (CapRover)**

```bash
# Real-time
caprover logs -a dd-dashboard -f

# DerniÃ¨res 100 lignes
caprover logs -a dd-dashboard --lines 100

# Filtrer par domaine
caprover logs -a dd-dashboard | grep "marseille"
```

### **Logs JSON (Pino)**

**Format :**
```json
{
  "level": 30,
  "time": 1703520000000,
  "domain": "devis-demenageur-marseille.fr",
  "rowsInserted": 1234,
  "duration": 5678,
  "msg": "Domain processed successfully"
}
```

**Niveaux :**
- `10` : TRACE (debug dÃ©taillÃ©)
- `20` : DEBUG
- `30` : INFO (dÃ©faut)
- `40` : WARN
- `50` : ERROR
- `60` : FATAL

---

## ğŸ†˜ Support

**ProblÃ¨me persistant ?**
- Consulter `STATUS.md` pour l'inventaire complet
- Consulter `CAPROVER-DEPLOY.md` pour le dÃ©ploiement
- GitHub Issues : [moverz_dashboard/issues](https://github.com/gdetaisne/moverz_dashboard/issues)

**Contact :**
- Email : guillaume@moverz.io

